#!/usr/bin/env ruby

require 'scout'
require 'scout-ai'

$0 = "scout-ai #{$previous_commands.any? ? $previous_commands*" " + " " : "" }#{ File.basename(__FILE__) }" if $previous_commands

options = SOPT.setup <<EOF
Ask an LLM model

$ #{$0} [<options>] [<question>]

Use STDIN to add context to the question. The context can be referenced using
three dots '...'. The model will be prompted with the question, unless the
inline option is used. If the chat option is used, the response will be added
to the end of the file. If the file option is used the file contents will be
prepended before the question.  With the template option, the file will be read
as if it were the question, and the actual question will be placed under the
characters '???', if they are present.

-h--help Print this help
-t--template* Use a template
-c--chat* Follow a conversation
-i--inline* Ask inline questions about a file
-f--file* Incorporate file at the start
-m--model* Model to use
-e--endpoint* Endpoint to use
-b--backend* Backend to use
-d--dry_run Dry run, don't ask
EOF
if options[:help]
  if defined? scout_usage
    scout_usage 
  else
    puts SOPT.doc
  end
  exit 0
end

Log.severity = options.delete(:log).to_i if options.include? :log

file, chat, inline, template, dry_run = IndiferentHash.process_options options, :file, :chat, :inline, :template, :dry_run

question = ARGV * " "

if template
  if Open.exists?(template)
    template_question = Open.read(template)
  else
    template_question = Scout.questions[template].read
  end
  if template_question.include?('???')
    question = template_question.sub('???', question)
  else
    question = template_question
  end
end

if question.include?('...')
  context = file ? Open.read(file) : STDIN.read
  question = question.sub('...', context)
elsif file
  question = "<file basename=#{File.basename file}>[[[\n" + Open.read(file) + "\n]]]</file>"
end

if chat
  conversation = Open.exist?(chat)? LLM.chat(chat) : [] 
  convo_options = LLM.options conversation
  conversation = question.empty? ? conversation : conversation +  LLM.chat(question)

  if dry_run
    ppp LLM.print conversation
    exit 0
  end
  new = LLM.ask(conversation, convo_options.merge(options.merge(return_messages: true)))
  conversation = Open.read(chat) + LLM.print(new)
  Open.write(chat, conversation)
elsif inline

  file = Open.read inline

  new_file = ""
  while true
    pre, question, post = 
      file.partition(/^\s*#\s*ask:(?:.*?)(?=^\s*[^\s#])/sm)

      break if post.empty?

    new_file << pre
    new_file << question
    clean_question = question.gsub('#', '').gsub(/\s+/,' ').sub(/.*ask:\s*/,'').strip
    chat = [
      {role: :system, content: "Write a succint reply with no commentary and no formatting."}, 
      {role: :user, content: "Find the following question as a comment in the file give a response to be placed inline: #{question}"},
      LLM.tag('file', file, inline)
    ]
    response = LLM.ask(LLM.chat(chat))
    new_file << <<-EOF
# Response start
#{response}
# Response end
    EOF
    file = post
  end
  new_file << file
  Open.write(inline, new_file)
else
  puts LLM.ask(question, options)
end
