#!/usr/bin/env ruby

require 'scout'
require 'scout-ai'
require 'scout/workflow'
require 'scout/knowledge_base'
require 'scout/llm/agent'

$0 = "scout #{$previous_commands.any? ? $previous_commands*" " + " " : "" }#{ File.basename(__FILE__) }" if $previous_commands

options = SOPT.setup <<EOF

Ask GPT

$ #{$0} [<options>] [question]

Use STDIN to add context to the question

-h--help Print this help
-l--log* Log level
-t--template* Use a template
-c--chat* Follow a conversation
-m--model* Model to use
-e--endpoint* Endpoint to use
-f--file* Incorporate file at the start
-wt--workflow_tasks* Export these tasks to the agent
EOF
if options[:help]
  if defined? scout_usage
    scout_usage 
  else
    puts SOPT.doc
  end
  exit 0
end

Log.severity = options.delete(:log).to_i if options.include? :log

file = options.delete(:file)

agent, *question_parts = ARGV

agent_dir = Scout.var.Agent[agent]
workflow_tasks = options.delete(:workflow_tasks)

workflow = begin
             if agent_dir.workflow.set_extension('rb').exists?
               Workflow.require_workflow agent_dir.workflow.set_extension('rb').find
             else
               Misc.with_env "SCOUT_WORKFLOW_AUTOINSTALL", false do
                 Workflow.require_workflow agent
               end
             end
           rescue
           end

if workflow_tasks and workflow
  workflow.clear_exports
  workflow.export_asynchronous *workflow_tasks.split(',')
end

knowledge_base = KnowledgeBase.load(agent_dir.knowledge_base) if agent_dir.knowledge_base.exists?
knowledge_base ||= begin workflow.knowledge_base rescue nil end || KnowledgeBase.new(agent_dir.knowledge_base)

agent = LLM::Agent.new **options.merge(workflow: workflow, knowledge_base: knowledge_base)

question = question_parts * " " 

if template = options.delete(:template)
  if Open.exists?(template)
    template_question = Open.read(template)
  else
    template_question = Scout.questions[template].read
  end
  if template_question.include?('???')
    question = template_question.sub('???', question)
  else
    question = template_question
  end
end

if question.include?('...')
  context = file ? Open.read(file) : STDIN.read 
  question = question.sub('...', context)
end

if chat
  conversation = Open.exist?(chat)? Open.read(chat) : "" 
  question = question.empty? ? conversation : conversation + "\nuser:\n" +  question
  new = LLM.ask(question, options)
  conversation = question + "\nassistant:\n" + new
  Open.write(chat, conversation)
else
  puts LLM.ask(question, options)
end
